# headfirstAI
This is inspired after a key book in Java which i have during my growing years in Tech, it is very good it starts with an usecase and then explains the details when the situation arises, on the tutorials i have found online there is no such feeling of adrenaline rush , this is an attempt to create such content, hope you like it.

If i interview a person on DL interview , i hope the person is good in basics of ML and DL, there are lot of theories on github repos but i will try to cover the applied aspect of the content.

most of the activitiy here will be done using pytorch. which will start with a problem statement and just reserach before going deep into the implemenation.

**challenge 0**:
implement a research paper from scratch

**challenge 1**:
can you classify text using Multilevel perceptron.i will give you the amazon review dataset tell me how you will approach it.

**challenge 2**:
can you take any other model and improve the performance in challenge 1, what is the response time.

**challenge 3**:
What is FlashAttention and how does it work?
can you write code for that?

**challenge 4**:
What is KV cache and why is it useful?

**challenge 5**:
Why is LLM inference memory-bounded?

**challenge 6**:
What are scaling laws for LLMs? what is the use for you regarding that?can you show me a demonstration.

**challenge 7**:
What is LoRA and how does it work?

**challenge 8**:
What is the difference between the Transformer and RNNs?

**challenge 9**:
Difference between LSTM and vanilla RNN.can you demo the code and explain the difference.

**challenge 10**
Difference between structured prediction and classification.

**challenge 11**
Difference between CRFs and HMMs.

**challenge 12**
What is the difference between a LM and a LLM?

**challenge 13**
Instruction tuning, in-context learning, RLHF, etc.

**challenge 14**
Pitfalls of n-gram-based metrics like ROUGE or BLEU.

**challenge 15**
Differences between encoder-only models, encoder-decoder models, and decoder-only models. Examples as well.

**challenge 16**:
Why do so many models seem to be decoder-only these days?

**challenge 17**:
Should be able to code basic transformers from scratch. Implement KV caching. Understand different positional encodings techniques.

**challenge 18**:
can you tell about below topics:
Evaluation
Fine-tuning techniques
RAGs
NLP fundamentals

Understanding how LLMs work (internals)

what are the evaluations
interview:(https://www.youtube.com/watch?v=sGqEKzJYrNE)

ROUGE, BLEU might work
https://blog.vespa.ai/improving-retrieval-with-llm-as-a-judge/

**challenge 19**:
quantization techniques AWQ GPTQ papers have you read them?

**challenge 20**:
hparameter tuning and parallelization techniques?

**challenge 21**:
go deep on finetuning what are the tradeoffs why you chose one over the other

**challenge 22**:
can you explain RAG and its various component**s?

**challenge 23**:
can you build agentic ai solution to search for needed information online.

**challenge 24**:
can you deploy the llm service for just 10 dollars a month? you are free to choose any framework.

**challenge 25:**
can you create a chatbot for FAQ from a website

**challenge 26**:
can you create a text summarization tool?

**challenge 27**:
 Sentiment Analysis on reviews dataset?

 **challenge 28**:
 can you create a talkative chatbot for understanding a concept

 **challenge 29**:
 Language Translation Service 

 **challenge 30**:
 Named Entity Recognition
 **challenge 31**:
 Text Classification for news articles

 **challenge 32**:
 Question Answering System

 **challenge 33**:
 Text Generation with RNN

 **challenge 34**:
 Paraphrase Detection 

 **challenge 35**:
Text-to-Speech (TTS) Synthesis

**challenge 36**:
Document Clustering


**challenge 37**:
Language Model Fine-Tuning

**challenge 38**:
Text Similarity Measurement

**challenge 39**:
Multi-Turn Dialogue System

**challenge 40**:
Document Summarization with Attention Mechanisms

**challenge 41**:
Text Generation with Transformers

**challenge 42**:
Named Entity Linking (NEL) System

**challenge 43**:
Speech Emotion Recognition

**challenge 44**:
Document-level Sentiment Analysis

**challenge 45**:
Youtube or Podcast Summarizer

**challenge 46**:
create a dataset for a domain of your choice.

**challenge 47**:
Deploy a model to aws sagemaker.

**challenge 48**:
take a github repo you like and add test cases to that and make a video of it

**challenge 49**:
use openbook kind of setup to learn all the above challenges.

**challenge 50**:
complete D2l.ai


